{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, pipeline\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import concurrent.futures\n",
    "import psutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_cleaned = pd.read_csv('Madrid_reviews_cleaned.csv')\n",
    "data_cleaned = pd.read_parquet('Madrid_reviews_cleaned.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned['clean_text'] = data_cleaned['clean_text'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>parse_count</th>\n",
       "      <th>restaurant_name</th>\n",
       "      <th>rating_review</th>\n",
       "      <th>sample</th>\n",
       "      <th>review_id</th>\n",
       "      <th>title_review</th>\n",
       "      <th>review_preview</th>\n",
       "      <th>review_full</th>\n",
       "      <th>date</th>\n",
       "      <th>...</th>\n",
       "      <th>emotion_disgust</th>\n",
       "      <th>emotion_fear</th>\n",
       "      <th>emotion_negative</th>\n",
       "      <th>emotion_sadness</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sushi_Yakuza</td>\n",
       "      <td>4</td>\n",
       "      <td>Positive</td>\n",
       "      <td>review_731778139</td>\n",
       "      <td>Good sushi option</td>\n",
       "      <td>The menu of Yakuza is a bit of a lottery, some...</td>\n",
       "      <td>The menu of Yakuza is a bit of a lottery, some...</td>\n",
       "      <td>2019-12-10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>75</td>\n",
       "      <td>55</td>\n",
       "      <td>4.240000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>menu yakuza bit lotteri plate realli good like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>Azotea_Forus_Barcelo</td>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>review_766657436</td>\n",
       "      <td>Light up your table at night</td>\n",
       "      <td>Check your bill when you cancel just in case y...</td>\n",
       "      <td>Check your bill when you cancel just in case y...</td>\n",
       "      <td>2020-08-23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>4.368421</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>check bill cancel case get extra charg surpris...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Level_Veggie_Bistro</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>review_749493592</td>\n",
       "      <td>Delicious</td>\n",
       "      <td>I had the yuca profiteroles and the veggie bur...</td>\n",
       "      <td>I had the yuca profiteroles and the veggie bur...</td>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>32</td>\n",
       "      <td>26</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yuca profiterol veggi burger recommend server ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>Sto_Globo_Sushi_Room</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>review_772422246</td>\n",
       "      <td>Loved this place</td>\n",
       "      <td>A friend recommended this place as one of the ...</td>\n",
       "      <td>A friend recommended this place as one of the ...</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85</td>\n",
       "      <td>62</td>\n",
       "      <td>4.270588</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>friend recommend place one best sushi ever tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Azotea_Forus_Barcelo</td>\n",
       "      <td>5</td>\n",
       "      <td>Positive</td>\n",
       "      <td>review_761855600</td>\n",
       "      <td>Amazing terrace in madrid</td>\n",
       "      <td>Amazing terrace in madrid - great atmosphere a...</td>\n",
       "      <td>Amazing terrace in madrid - great atmosphere a...</td>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21</td>\n",
       "      <td>20</td>\n",
       "      <td>4.714286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>amaz terrac madrid great atmospher great wine ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  parse_count       restaurant_name  rating_review    sample  \\\n",
       "0           0            1          Sushi_Yakuza              4  Positive   \n",
       "1          10           11  Azotea_Forus_Barcelo              1  Negative   \n",
       "2          11           12   Level_Veggie_Bistro              5  Positive   \n",
       "3          12           13  Sto_Globo_Sushi_Room              5  Positive   \n",
       "4          13           14  Azotea_Forus_Barcelo              5  Positive   \n",
       "\n",
       "          review_id                  title_review  \\\n",
       "0  review_731778139             Good sushi option   \n",
       "1  review_766657436  Light up your table at night   \n",
       "2  review_749493592                     Delicious   \n",
       "3  review_772422246             Loved this place    \n",
       "4  review_761855600     Amazing terrace in madrid   \n",
       "\n",
       "                                      review_preview  \\\n",
       "0  The menu of Yakuza is a bit of a lottery, some...   \n",
       "1  Check your bill when you cancel just in case y...   \n",
       "2  I had the yuca profiteroles and the veggie bur...   \n",
       "3  A friend recommended this place as one of the ...   \n",
       "4  Amazing terrace in madrid - great atmosphere a...   \n",
       "\n",
       "                                         review_full        date  ...  \\\n",
       "0  The menu of Yakuza is a bit of a lottery, some...  2019-12-10  ...   \n",
       "1  Check your bill when you cancel just in case y...  2020-08-23  ...   \n",
       "2  I had the yuca profiteroles and the veggie bur...  2020-03-06  ...   \n",
       "3  A friend recommended this place as one of the ...  2020-09-29  ...   \n",
       "4  Amazing terrace in madrid - great atmosphere a...  2020-07-27  ...   \n",
       "\n",
       "  emotion_disgust emotion_fear emotion_negative  emotion_sadness  word_count  \\\n",
       "0        0.058824     0.117647         0.117647         0.058824          75   \n",
       "1        0.000000     0.166667         0.250000         0.166667          38   \n",
       "2        0.000000     0.000000         0.200000         0.000000          32   \n",
       "3        0.000000     0.000000         0.076923         0.000000          85   \n",
       "4        0.000000     0.000000         0.000000         0.000000          21   \n",
       "\n",
       "   unique_word_count  mean_word_length  hashtag_count  mention_count  \\\n",
       "0                 55          4.240000              0              0   \n",
       "1                 35          4.368421              0              0   \n",
       "2                 26          5.000000              0              0   \n",
       "3                 62          4.270588              0              0   \n",
       "4                 20          4.714286              0              0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  menu yakuza bit lotteri plate realli good like...  \n",
       "1  check bill cancel case get extra charg surpris...  \n",
       "2  yuca profiterol veggi burger recommend server ...  \n",
       "3  friend recommend place one best sushi ever tri...  \n",
       "4  amaz terrac madrid great atmospher great wine ...  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned['review_full'] = data_cleaned['review_full'].astype(str) \n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot Classification - Restaurant Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create the zero-shot classification pipeline\n",
    "def create_classifier(model_name):\n",
    "    return pipeline(\"zero-shot-classification\", model=model_name)\n",
    "\n",
    "# Function to classify a single piece of text\n",
    "def classify_text(text, classifier, labels):\n",
    "    result = classifier(text, labels)\n",
    "    return result['labels'][0]  # The label with the highest score\n",
    "\n",
    "# Check available memory\n",
    "def get_available_memory():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / (1024 ** 2)  # Return memory usage in MB\n",
    "\n",
    "# Function to classify text in parallel\n",
    "def parallel_classify_texts(texts, classifier, labels, num_threads):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        results = list(tqdm(executor.map(lambda text: classify_text(text, classifier, labels), texts), total=len(texts)))\n",
    "    return results\n",
    "\n",
    "# Process the DataFrame in chunks and save each chunk to a CSV\n",
    "def process_and_save_chunks(data, chunk_size, num_threads, output_dir, model_name, labels):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "    chunks = [data[i:i + chunk_size] for i in range(0, data.shape[0], chunk_size)]\n",
    "    \n",
    "    classifier = create_classifier(model_name)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk['predicted_label'] = parallel_classify_texts(chunk['review_full'], classifier, labels, num_threads)\n",
    "\n",
    "        # Optionally, convert labels to ratings\n",
    "        def convert_label_to_rating(label):\n",
    "            label_to_rating = {\n",
    "                \"very bad review\": 1,\n",
    "                \"bad review\": 2,\n",
    "                \"average review\": 3,\n",
    "                \"good review\": 4,\n",
    "                \"very good review\": 5\n",
    "            }\n",
    "            return label_to_rating[label]\n",
    "\n",
    "        chunk['predicted_rating'] = chunk['predicted_label'].apply(convert_label_to_rating)\n",
    "\n",
    "        # Save the chunk to a CSV file\n",
    "        chunk.to_csv(os.path.join(output_dir, f'chunk_{i}.csv'), index=False)\n",
    "\n",
    "        # Print progress\n",
    "        print(f'Saved chunk {i} to CSV.')\n",
    "\n",
    "\n",
    "def read_all_csvs_in_folder(folder_path):\n",
    "    # List to hold the individual DataFrames\n",
    "    df_list = []\n",
    "\n",
    "    # Iterate over all files in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file is a CSV file\n",
    "        if filename.endswith('.csv'):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Read the CSV file into a DataFrame\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Append the DataFrame to the list\n",
    "            df_list.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames in the list into a single DataFrame\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    return combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "with open(\"config.json\", \"r\") as f:\n",
    "    config = json.load(f)\n",
    "    hf_api_token = config[\"hugging_face\"][\"api_token\"]\n",
    "\n",
    "# Set Hugging Face API token as an environment variable\n",
    "os.environ[\"HF_HOME\"] = config[\"hugging_face\"][\"api_token\"]\n",
    "token = config[\"hugging_face\"][\"api_token\"]\n",
    "login(token=token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = \"meta-llama/Llama-2-7b-hf\"\n",
    "labels = [\"very bad review\", \"bad review\", \"average review\", \"good review\", \"very good review\"]\n",
    "output_dir='processed_chunks_' + model\n",
    "\n",
    "process_and_save_chunks(data_cleaned, chunk_size=1000, num_threads=4, output_dir=output_dir, model_name=model, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We attempted to run llama both locally and on colab however, it would kill the kernel while loading the model. Given more computing power we would attempt other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bart-large-mnli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = \"facebook/bart-large-mnli\"\n",
    "labels = [\"very bad review\", \"bad review\", \"average review\", \"good review\", \"very good review\"]\n",
    "output_dir='processed_chunks_bart'\n",
    "# process_and_save_chunks(data_cleaned, chunk_size=1000, num_threads=4, output_dir=output_dir, model_name=model, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_rating\n",
       "1    0.006\n",
       "2    0.046\n",
       "3    0.019\n",
       "4    0.520\n",
       "5    0.409\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bart = read_all_csvs_in_folder(output_dir)\n",
    "bart['rating_diff']=bart['predicted_rating']-bart['rating_review']\n",
    "bart['predicted_rating'].value_counts().sort_index()\n",
    "percent_of_total = bart['predicted_rating'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_diff\n",
       "-3    0.001\n",
       "-2    0.001\n",
       "-1    0.440\n",
       " 0    0.508\n",
       " 1    0.046\n",
       " 2    0.004\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_diff_counts = bart['rating_diff'].value_counts().sort_index()\n",
    "percent_of_total = bart['rating_diff'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = \"roberta-large-mnli\"\n",
    "labels = [\"very bad review\", \"bad review\", \"average review\", \"good review\", \"very good review\"]\n",
    "output_dir='processed_chunks_roberta'\n",
    "\n",
    "# process_and_save_chunks(data_cleaned, chunk_size=1000, num_threads=4, output_dir=output_dir, model_name=model, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_rating\n",
       "1    0.009723\n",
       "2    0.032383\n",
       "3    0.052213\n",
       "4    0.831106\n",
       "5    0.074574\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta = read_all_csvs_in_folder(output_dir)\n",
    "roberta['rating_diff']=roberta['predicted_rating']-roberta['rating_review']\n",
    "roberta['predicted_rating'].value_counts().sort_index()\n",
    "percent_of_total = roberta['predicted_rating'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_diff\n",
       "-4    0.000064\n",
       "-3    0.001596\n",
       "-2    0.008596\n",
       "-1    0.688574\n",
       " 0    0.262170\n",
       " 1    0.032894\n",
       " 2    0.004362\n",
       " 3    0.001383\n",
       " 4    0.000362\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_diff_counts = roberta['rating_diff'].value_counts().sort_index()\n",
    "percent_of_total = roberta['rating_diff'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "labels = [\"very bad review\", \"bad review\", \"average review\", \"good review\", \"very good review\"]\n",
    "output_dir='processed_chunks_deberta'\n",
    "\n",
    "# process_and_save_chunks(data_cleaned, chunk_size=1000, num_threads=4, output_dir=output_dir, model_name=model, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_rating\n",
       "1    0.009723\n",
       "2    0.032383\n",
       "3    0.052213\n",
       "4    0.831106\n",
       "5    0.074574\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deberta = read_all_csvs_in_folder(output_dir)\n",
    "deberta['rating_diff']=deberta['predicted_rating']-deberta['rating_review']\n",
    "deberta['predicted_rating'].value_counts().sort_index()\n",
    "percent_of_total = roberta['predicted_rating'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_diff\n",
       "-4    0.00006\n",
       "-3    0.00386\n",
       "-2    0.01224\n",
       "-1    0.35848\n",
       " 0    0.53956\n",
       " 1    0.07870\n",
       " 2    0.00518\n",
       " 3    0.00162\n",
       " 4    0.00030\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_diff_counts = deberta['rating_diff'].value_counts().sort_index()\n",
    "percent_of_total = deberta['rating_diff'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = \"distilbert/distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "labels = [\"very bad review\", \"bad review\", \"average review\", \"good review\", \"very good review\"]\n",
    "output_dir='processed_chunks_distilbert'\n",
    "\n",
    "# process_and_save_chunks(data_cleaned, chunk_size=1000, num_threads=4, output_dir=output_dir, model_name=model, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_rating\n",
       "1    0.009723\n",
       "2    0.032383\n",
       "3    0.052213\n",
       "4    0.831106\n",
       "5    0.074574\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert = read_all_csvs_in_folder(output_dir)\n",
    "distilbert['rating_diff']=distilbert['predicted_rating']-distilbert['rating_review']\n",
    "distilbert['predicted_rating'].value_counts().sort_index()\n",
    "percent_of_total = roberta['predicted_rating'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_diff\n",
       "-3    0.001333\n",
       "-1    0.002333\n",
       " 0    0.793000\n",
       " 1    0.138667\n",
       " 2    0.036000\n",
       " 3    0.017000\n",
       " 4    0.011667\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_diff_counts = distilbert['rating_diff'].value_counts().sort_index()\n",
    "percent_of_total = distilbert['rating_diff'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flan T-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = \"sjrhuschlee/flan-t5-base-mnli\"\n",
    "labels = [\"very bad review\", \"bad review\", \"average review\", \"good review\", \"very good review\"]\n",
    "output_dir='processed_chunks_flan-t5'\n",
    "\n",
    "# process_and_save_chunks(data_cleaned, chunk_size=1000, num_threads=4, output_dir=output_dir, model_name=model, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_rating\n",
       "1    0.009723\n",
       "2    0.032383\n",
       "3    0.052213\n",
       "4    0.831106\n",
       "5    0.074574\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flan_t5 = read_all_csvs_in_folder(output_dir)\n",
    "flan_t5['rating_diff']=flan_t5['predicted_rating']-flan_t5['rating_review']\n",
    "flan_t5['predicted_rating'].value_counts().sort_index()\n",
    "percent_of_total = roberta['predicted_rating'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating_diff\n",
       "-4    0.0010\n",
       "-3    0.0310\n",
       "-2    0.0065\n",
       "-1    0.3395\n",
       " 0    0.5325\n",
       " 1    0.0650\n",
       " 2    0.0155\n",
       " 3    0.0080\n",
       " 4    0.0010\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_diff_counts = flan_t5['rating_diff'].value_counts().sort_index()\n",
    "percent_of_total = flan_t5['rating_diff'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rating  flan_t5  distilBERT  deBERTa   RoBERTa   bart\n",
      "0       1   0.0020    0.000000  0.00494  0.009723  0.006\n",
      "1       2   0.0555    0.002000  0.05592  0.032383  0.046\n",
      "2       3   0.0025    0.000000  0.03060  0.052213  0.019\n",
      "3       4   0.4555    0.003333  0.46050  0.831106  0.520\n",
      "4       5   0.4845    0.994667  0.44804  0.074574  0.409\n"
     ]
    }
   ],
   "source": [
    "dataframes = {\n",
    "    'flan_t5': flan_t5,\n",
    "    'distilBERT': distilbert,\n",
    "    'deBERTa': deberta,\n",
    "    'RoBERTa': roberta,\n",
    "    'bart': bart\n",
    "}\n",
    "\n",
    "# Create an empty list to store the value_counts dataframes\n",
    "count_dfs = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    counts = df['predicted_rating'].value_counts(normalize=True).sort_index()\n",
    "    counts_df = counts.reset_index()\n",
    "    counts_df.columns = ['rating', name]\n",
    "    count_dfs.append(counts_df)\n",
    "\n",
    "# Merge all count dataframes on the 'rating' column\n",
    "result_df = count_dfs[0]\n",
    "for count_df in count_dfs[1:]:\n",
    "    result_df = result_df.merge(count_df, on='rating', how='outer')\n",
    "\n",
    "# Fill NaN values with 0 (optional, if you expect missing ratings)\n",
    "result_df = result_df.fillna(0)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rating_diff  flan_t5  distilBERT  deBERTa   RoBERTa   bart\n",
      "0           -4   0.0010    0.000000  0.00006  0.000064  0.000\n",
      "1           -3   0.0310    0.001333  0.00386  0.001596  0.001\n",
      "2           -2   0.0065    0.000000  0.01224  0.008596  0.001\n",
      "3           -1   0.3395    0.002333  0.35848  0.688574  0.440\n",
      "4            0   0.5325    0.793000  0.53956  0.262170  0.508\n",
      "5            1   0.0650    0.138667  0.07870  0.032894  0.046\n",
      "6            2   0.0155    0.036000  0.00518  0.004362  0.004\n",
      "7            3   0.0080    0.017000  0.00162  0.001383  0.000\n",
      "8            4   0.0010    0.011667  0.00030  0.000362  0.000\n"
     ]
    }
   ],
   "source": [
    "count_dfs = []\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    counts = df['rating_diff'].value_counts(normalize=True).sort_index()\n",
    "    counts_df = counts.reset_index()\n",
    "    counts_df.columns = ['rating_diff', name]\n",
    "    count_dfs.append(counts_df)\n",
    "\n",
    "# Merge all count dataframes on the 'rating' column\n",
    "result_df = count_dfs[0]\n",
    "for count_df in count_dfs[1:]:\n",
    "    result_df = result_df.merge(count_df, on='rating_diff', how='outer')\n",
    "\n",
    "# Fill NaN values with 0 (optional, if you expect missing ratings)\n",
    "result_df = result_df.fillna(0)\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges Encountered "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oringinally the text given to the classifier was a cleaned text and the labels given were:\n",
    "```python\n",
    "['very bad', 'bad', 'neutral', 'good', 'very good']\n",
    "```\n",
    "However with this approache we encountered a problem, some rating were extremely misclassified. The idea of conducting zero-shot calssification is that the rating itself would be free from bias. However, scathing reviews were given a 4/5 which would be too inacurrate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Image Description](images/misclassification.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The solution was to change the clean text for the review_full column and change the labels to:\n",
    "```python\n",
    "[\"very bad review\", \"bad review\", \"average review\", \"good review\", \"very good review\"]\n",
    "```\n",
    "This allows the classifier to infer more context on the nature of the task and classifies more accurately. Below is an example of the differences in performance. rating_review is the user rating, dirty_text is the review_full column, clean_text is the processed text, and review_in_label in the version we used with review full and the above labels.\n",
    "\n",
    "![Image Description](images/comparing_roberta_models.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero Shot Classification - Restaurant Cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "import concurrent.futures\n",
    "import os\n",
    "\n",
    "# Function to create the zero-shot classification pipeline\n",
    "def create_classifier(model_name):\n",
    "    return pipeline(\"zero-shot-classification\", model=model_name)\n",
    "\n",
    "# Function to classify a single piece of text\n",
    "def classify_text(row, classifier, labels):\n",
    "    text = f\"Restaurant Name: {row['restaurant_name']} - Review Title: {row['title_review']} - Review Full: {row['review_full']}\"\n",
    "    result = classifier(text, labels)\n",
    "    return result['labels'][0]  # The label with the highest score\n",
    "\n",
    "# Check available memory\n",
    "def get_available_memory():\n",
    "    import psutil\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / (1024 ** 2)  # Return memory usage in MB\n",
    "\n",
    "# Define chunk size\n",
    "chunk_size = 1000  # Adjust as needed\n",
    "\n",
    "# Number of threads to use (adjust as needed)\n",
    "num_threads = 4  # Use a small number of threads to limit CPU usage\n",
    "\n",
    "# Wrap your pandas apply with tqdm for a progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "# Function to classify text in parallel\n",
    "def parallel_classify_texts(df, classifier, labels, num_threads):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        results = list(tqdm(executor.map(lambda row: classify_text(row, classifier, labels), [row for _, row in df.iterrows()]), total=len(df)))\n",
    "    return results\n",
    "\n",
    "# Process the DataFrame in chunks and save each chunk to a CSV\n",
    "def process_and_save_chunks(data, chunk_size, num_threads, output_dir, file_name, model_name, labels):\n",
    "    os.makedirs(output_dir, exist_ok=True)  # Create the output directory if it doesn't exist\n",
    "    chunks = [data[i:i + chunk_size] for i in range(0, data.shape[0], chunk_size)]\n",
    "    \n",
    "    classifier = create_classifier(model_name)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        chunk['predicted_cuisine'] = parallel_classify_texts(chunk, classifier, labels, num_threads)\n",
    "        output_file_path = os.path.join(output_dir, f'{os.path.splitext(file_name)[0]}_chunk_{i}.csv')\n",
    "        # Save the chunk to a CSV file\n",
    "        chunk.to_csv(output_file_path, index=False)\n",
    "        # Print progress\n",
    "        print(f'Saved chunk {i} of {file_name} to CSV.')\n",
    "\n",
    "# Process all CSV files in a directory\n",
    "def process_all_csvs(input_dir, output_dir, model_name, labels):\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(input_dir, file_name)\n",
    "            print(f'Processing file: {file_path}')\n",
    "            data = pd.read_csv(file_path)\n",
    "            process_and_save_chunks(data, chunk_size, num_threads, output_dir, file_name, model_name, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "input_dir = 'processed_chunks_roberta'\n",
    "output_dir = 'processed_chunks_roberta_cuisine'\n",
    "\n",
    "# Define model and labels\n",
    "model_name = \"roberta-large-mnli\"\n",
    "cuisine_labels = [\"Italian\", \"Chinese\", \"Mexican\", \"Indian\", \"French\", \"Japanese\", \"American\", \"Thai\", \"Spanish\", \"Greek\"]\n",
    "\n",
    "# process_all_csvs(input_dir, output_dir, model_name, cuisine_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_cuisine\n",
       "American    0.047556\n",
       "Chinese     0.007444\n",
       "French      0.133111\n",
       "Greek       0.039667\n",
       "Indian      0.020833\n",
       "Italian     0.066444\n",
       "Japanese    0.017944\n",
       "Mexican     0.154556\n",
       "Spanish     0.502444\n",
       "Thai        0.010000\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_cuisine = read_all_csvs_in_folder(output_dir)\n",
    "percent_of_total = roberta_cuisine['predicted_cuisine'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>restaurant_name</th>\n",
       "      <th>A_Nora</th>\n",
       "      <th>A_vAnvera</th>\n",
       "      <th>Al_Son_de_Cuba</th>\n",
       "      <th>Albora</th>\n",
       "      <th>Alcaravea_castello</th>\n",
       "      <th>AlliOli_Valencian_Food</th>\n",
       "      <th>Alright</th>\n",
       "      <th>Amicis</th>\n",
       "      <th>Amparito_Roca</th>\n",
       "      <th>Antigua_Casa_de_la_Paella</th>\n",
       "      <th>...</th>\n",
       "      <th>Triana</th>\n",
       "      <th>Txirimiri</th>\n",
       "      <th>Verdejo</th>\n",
       "      <th>Vietnam_Restaurante</th>\n",
       "      <th>Vila_Brasil</th>\n",
       "      <th>Vinos_de_Bellota</th>\n",
       "      <th>YOUnique_Restaurant</th>\n",
       "      <th>Yakiniku_Rikyu</th>\n",
       "      <th>Yakitoro_by_Chicote</th>\n",
       "      <th>Zenith_Brunch_Cocktails</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>American</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>French</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greek</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indian</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italian</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japanese</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexican</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>30</td>\n",
       "      <td>158</td>\n",
       "      <td>7</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>62</td>\n",
       "      <td>19</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>108</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thai</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "restaurant_name    A_Nora  A_vAnvera  Al_Son_de_Cuba  Albora  \\\n",
       "predicted_cuisine                                              \n",
       "American                0          0               0       0   \n",
       "Chinese                 0          0               0       0   \n",
       "French                  0          2               0       4   \n",
       "Greek                   1          1               0       2   \n",
       "Indian                  0          0               0       0   \n",
       "Italian                 0         36               0       1   \n",
       "Japanese                0          0               0       0   \n",
       "Mexican                 0          0               0       0   \n",
       "Spanish                 2         11               4       3   \n",
       "Thai                    0          0               0       0   \n",
       "\n",
       "restaurant_name    Alcaravea_castello  AlliOli_Valencian_Food  Alright  \\\n",
       "predicted_cuisine                                                        \n",
       "American                            0                       0       49   \n",
       "Chinese                             0                       0        0   \n",
       "French                              0                       0        2   \n",
       "Greek                               0                       0        2   \n",
       "Indian                              0                       0        1   \n",
       "Italian                             0                       0        2   \n",
       "Japanese                            0                       0        0   \n",
       "Mexican                             0                       0        4   \n",
       "Spanish                             7                      23       30   \n",
       "Thai                                0                       0        0   \n",
       "\n",
       "restaurant_name    Amicis  Amparito_Roca  Antigua_Casa_de_la_Paella  ...  \\\n",
       "predicted_cuisine                                                    ...   \n",
       "American                9              0                          0  ...   \n",
       "Chinese                 0              0                          0  ...   \n",
       "French                 13              1                          0  ...   \n",
       "Greek                 151              0                          0  ...   \n",
       "Indian                  1              0                          0  ...   \n",
       "Italian                26              0                          0  ...   \n",
       "Japanese                0              0                          0  ...   \n",
       "Mexican                18              3                          5  ...   \n",
       "Spanish               158              7                         40  ...   \n",
       "Thai                    0              0                          0  ...   \n",
       "\n",
       "restaurant_name    Triana  Txirimiri  Verdejo  Vietnam_Restaurante  \\\n",
       "predicted_cuisine                                                    \n",
       "American                0          0        0                    0   \n",
       "Chinese                 0          0        0                    6   \n",
       "French                  1          7        0                    3   \n",
       "Greek                  10          8        0                    0   \n",
       "Indian                  0          1        0                    2   \n",
       "Italian                 0          1        0                    0   \n",
       "Japanese                0          0        0                    0   \n",
       "Mexican                 9         41        0                    0   \n",
       "Spanish                14         62       19                   16   \n",
       "Thai                    0          0        0                    8   \n",
       "\n",
       "restaurant_name    Vila_Brasil  Vinos_de_Bellota  YOUnique_Restaurant  \\\n",
       "predicted_cuisine                                                       \n",
       "American                     0                 1                    0   \n",
       "Chinese                      0                 0                    0   \n",
       "French                       0                28                   28   \n",
       "Greek                        0                 3                    0   \n",
       "Indian                       0                 0                    0   \n",
       "Italian                      0                 1                    2   \n",
       "Japanese                     0                 0                    0   \n",
       "Mexican                     11                14                    0   \n",
       "Spanish                     12               108                    9   \n",
       "Thai                         0                 0                    0   \n",
       "\n",
       "restaurant_name    Yakiniku_Rikyu  Yakitoro_by_Chicote  \\\n",
       "predicted_cuisine                                        \n",
       "American                        0                    0   \n",
       "Chinese                         0                    1   \n",
       "French                          0                   19   \n",
       "Greek                           0                    0   \n",
       "Indian                          0                    2   \n",
       "Italian                         0                    0   \n",
       "Japanese                        5                   16   \n",
       "Mexican                         0                   11   \n",
       "Spanish                         0                   17   \n",
       "Thai                            0                    0   \n",
       "\n",
       "restaurant_name    Zenith_Brunch_Cocktails  \n",
       "predicted_cuisine                           \n",
       "American                               138  \n",
       "Chinese                                  0  \n",
       "French                                  42  \n",
       "Greek                                    6  \n",
       "Indian                                   1  \n",
       "Italian                                  0  \n",
       "Japanese                                 0  \n",
       "Mexican                                  1  \n",
       "Spanish                                 93  \n",
       "Thai                                     0  \n",
       "\n",
       "[10 rows x 216 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table = pd.pivot_table(\n",
    "        roberta_cuisine,\n",
    "        index='predicted_cuisine',\n",
    "        columns='restaurant_name',\n",
    "        values='review_id',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "input_dir = 'processed_chunks_deberta'\n",
    "output_dir = 'processed_chunks_deberta_cuisine'\n",
    "\n",
    "# Define model and labels\n",
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "cuisine_labels = [\"Italian\", \"Chinese\", \"Mexican\", \"Indian\", \"French\", \"Japanese\", \"American\", \"Thai\", \"Spanish\", \"Greek\"]\n",
    "\n",
    "# process_all_csvs(input_dir, output_dir, model_name, cuisine_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predicted_cuisine\n",
       "American    0.031316\n",
       "Chinese     0.004684\n",
       "French      0.119289\n",
       "Greek       0.006158\n",
       "Indian      0.020605\n",
       "Italian     0.136895\n",
       "Japanese    0.024395\n",
       "Mexican     0.020921\n",
       "Spanish     0.630474\n",
       "Thai        0.005263\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_cuisine = read_all_csvs_in_folder(output_dir)\n",
    "percent_of_total = roberta_cuisine['predicted_cuisine'].value_counts(normalize=True).sort_index() \n",
    "percent_of_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>restaurant_name</th>\n",
       "      <th>99_Sushi_Bar</th>\n",
       "      <th>99_Sushi_Bar_Padre_Damian</th>\n",
       "      <th>A_Barra</th>\n",
       "      <th>A_vAnvera</th>\n",
       "      <th>Abaceria_Tapas_Lambuzo_Conchas</th>\n",
       "      <th>Ablanedo</th>\n",
       "      <th>Adrede</th>\n",
       "      <th>Albora</th>\n",
       "      <th>Alcaravea</th>\n",
       "      <th>Alcaravea_castello</th>\n",
       "      <th>...</th>\n",
       "      <th>Vila_Brasil</th>\n",
       "      <th>Villoldo</th>\n",
       "      <th>Vinitus_Gran_Via_Madrid</th>\n",
       "      <th>Vinos_de_Bellota</th>\n",
       "      <th>Vinoteca_Garcia_de_la_Navarra</th>\n",
       "      <th>Viridiana</th>\n",
       "      <th>Yakiniku_Rikyu</th>\n",
       "      <th>Yokaloka</th>\n",
       "      <th>Zalacain</th>\n",
       "      <th>Zenith_Brunch_Cocktails</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted_cuisine</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>American</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chinese</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>French</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greek</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Indian</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italian</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japanese</th>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexican</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish</th>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>47</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>79</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>9</td>\n",
       "      <td>64</td>\n",
       "      <td>85</td>\n",
       "      <td>92</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thai</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 364 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "restaurant_name    99_Sushi_Bar  99_Sushi_Bar_Padre_Damian  A_Barra  \\\n",
       "predicted_cuisine                                                     \n",
       "American                      2                          1        0   \n",
       "Chinese                       0                          0        0   \n",
       "French                        1                          0        6   \n",
       "Greek                         0                          0        0   \n",
       "Indian                        0                          0        1   \n",
       "Italian                       0                          0        9   \n",
       "Japanese                     36                         20        0   \n",
       "Mexican                       0                          0        0   \n",
       "Spanish                      13                          8       38   \n",
       "Thai                          0                          0        0   \n",
       "\n",
       "restaurant_name    A_vAnvera  Abaceria_Tapas_Lambuzo_Conchas  Ablanedo  \\\n",
       "predicted_cuisine                                                        \n",
       "American                   0                               0         0   \n",
       "Chinese                    0                               0         0   \n",
       "French                     0                               0         0   \n",
       "Greek                      0                               0         0   \n",
       "Indian                     0                               0         0   \n",
       "Italian                   38                               6         2   \n",
       "Japanese                   0                               0         0   \n",
       "Mexican                    0                               0         0   \n",
       "Spanish                   13                              47         5   \n",
       "Thai                       0                               0         0   \n",
       "\n",
       "restaurant_name    Adrede  Albora  Alcaravea  Alcaravea_castello  ...  \\\n",
       "predicted_cuisine                                                 ...   \n",
       "American                0       0          2                   0  ...   \n",
       "Chinese                 0       0          0                   0  ...   \n",
       "French                 15       1          1                   0  ...   \n",
       "Greek                   0       0          0                   0  ...   \n",
       "Indian                  0       0          0                   0  ...   \n",
       "Italian                 0       4          7                   2  ...   \n",
       "Japanese                0       0          1                   0  ...   \n",
       "Mexican                 0       0          0                   0  ...   \n",
       "Spanish                24       5         79                   5  ...   \n",
       "Thai                    0       0          0                   0  ...   \n",
       "\n",
       "restaurant_name    Vila_Brasil  Villoldo  Vinitus_Gran_Via_Madrid  \\\n",
       "predicted_cuisine                                                   \n",
       "American                     6         0                        0   \n",
       "Chinese                      0         0                        0   \n",
       "French                       1         1                        0   \n",
       "Greek                        0         0                        0   \n",
       "Indian                       0         0                        0   \n",
       "Italian                      2         4                        0   \n",
       "Japanese                     0         0                        0   \n",
       "Mexican                      0         0                        0   \n",
       "Spanish                     99         9                       64   \n",
       "Thai                         0         0                        0   \n",
       "\n",
       "restaurant_name    Vinos_de_Bellota  Vinoteca_Garcia_de_la_Navarra  Viridiana  \\\n",
       "predicted_cuisine                                                               \n",
       "American                          1                              1          0   \n",
       "Chinese                           0                              0          0   \n",
       "French                           50                              5          1   \n",
       "Greek                             0                              0          0   \n",
       "Indian                            0                              0          0   \n",
       "Italian                          18                             22          0   \n",
       "Japanese                          0                              0          0   \n",
       "Mexican                           1                              0          0   \n",
       "Spanish                          85                             92          9   \n",
       "Thai                              0                              0          0   \n",
       "\n",
       "restaurant_name    Yakiniku_Rikyu  Yokaloka  Zalacain  Zenith_Brunch_Cocktails  \n",
       "predicted_cuisine                                                               \n",
       "American                        0         0         1                       99  \n",
       "Chinese                         0         0         1                        3  \n",
       "French                          0         1        41                       65  \n",
       "Greek                           0         0         0                        4  \n",
       "Indian                          0         0         0                        1  \n",
       "Italian                         0         0         6                        7  \n",
       "Japanese                        5        40         0                        6  \n",
       "Mexican                         0         0         0                        2  \n",
       "Spanish                         0         9        53                      119  \n",
       "Thai                            0         0         0                        5  \n",
       "\n",
       "[10 rows x 364 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_table = pd.pivot_table(\n",
    "        roberta_cuisine,\n",
    "        index='predicted_cuisine',\n",
    "        columns='restaurant_name',\n",
    "        values='review_id',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = read_all_csvs_in_folder('processed_chunks_roberta')\n",
    "cuisine_roberta = read_all_csvs_in_folder('processed_chunks_roberta_cuisine')\n",
    "\n",
    "\n",
    "deberta = read_all_csvs_in_folder('processed_chunks_deberta')\n",
    "cuisine_deberta = read_all_csvs_in_folder('processed_chunks_deberta_cuisine')\n",
    "\n",
    "\n",
    "roberta['model_used']='RoBERTa'\n",
    "roberta['rating_diff']=roberta['predicted_rating']-roberta['rating_review']\n",
    "\n",
    "cuisine_roberta['model_used']='RoBERTa'\n",
    "cuisine_roberta['rating_diff']=cuisine_roberta['predicted_rating']-cuisine_roberta['rating_review']\n",
    "\n",
    "\n",
    "deberta['model_used']='DeBERTa'\n",
    "deberta['rating_diff']=deberta['predicted_rating']-deberta['rating_review']\n",
    "\n",
    "cuisine_deberta['model_used']='DeBERTa'\n",
    "cuisine_deberta['rating_diff']=cuisine_deberta['predicted_rating']-cuisine_deberta['rating_review']\n",
    "\n",
    "pd.concat([roberta, deberta]).to_csv('data_final_no_cuisine.csv', index=False)\n",
    "pd.concat([cuisine_roberta, cuisine_deberta]).to_csv('data_final_cuisine.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
